# -*- coding: utf-8 -*-
"""covidCoughClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VKGqg6nnOpTCvOpGjATv1dNG47TPxmWY
"""

import IPython.display as ipd
positiveSampleFilepath = "/content/drive/MyDrive/MiniProject2/Dataset/pos16kHz/05acPS4aRGfvuOfku11Za8zve8i2_heavy_2.wav"
ipd.Audio(positiveSampleFilepath)

negativeSampleFilepath = "/content/drive/MyDrive/MiniProject2/Dataset/neg16kHz/01OCEf1yB4czsq8ygRoT51s96Ba2_shallow_3.wav"
ipd.Audio(negativeSampleFilepath)

import librosa 
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
data, sample_rate = librosa.load(positiveSampleFilepath)
plt.figure(figsize=(12, 5))
librosa.display.waveshow(data, sr=sample_rate)

mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)
print(mfccs.shape)
print(mfccs)

data, sample_rate = librosa.load(negativeSampleFilepath)
plt.figure(figsize=(12, 5))
librosa.display.waveshow(data, sr=sample_rate)

mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)
print(mfccs.shape)
print(mfccs)

import numpy as np
import matplotlib.pyplot as plt
import IPython.display as display
import librosa
import librosa.display
from keras.preprocessing.image import ImageDataGenerator

variable=0
for i in range(0,1):
  sample_path = "/content/drive/MyDrive/MiniProject2/Dataset/pos16kHz/05acPS4aRGfvuOfku11Za8zve8i2_heavy_2.wav"
  librosa_audio_data,librosa_sample_rate=librosa.load(sample_path)
  variable=variable+1
  print(sample_path)
  display.Audio(sample_path)
  y, sr = librosa.load(sample_path)

  S = librosa.feature.melspectrogram(y, sr=sr)
  S_DB = librosa.amplitude_to_db(S, ref=np.max)
  plt.figure(figsize=(15, 5))
  librosa.display.specshow(S_DB, sr=sr, hop_length=512,
                          x_axis='time', y_axis='log')
  plt.colorbar()
  plt.title("Mel spectrogram", fontsize=20)
  plt.show()

variable=0
for i in range(0,1):
  sample_path = "/content/drive/MyDrive/MiniProject2/Dataset/neg16kHz/01OCEf1yB4czsq8ygRoT51s96Ba2_shallow_3.wav"
  librosa_audio_data,librosa_sample_rate=librosa.load(sample_path)
  variable=variable+1
  print(sample_path)
  display.Audio(sample_path)
  y, sr = librosa.load(sample_path)

  S = librosa.feature.melspectrogram(y, sr=sr)
  S_DB = librosa.amplitude_to_db(S, ref=np.max)
  plt.figure(figsize=(15, 5))
  librosa.display.specshow(S_DB, sr=sr, hop_length=512,
                          x_axis='time', y_axis='log')
  plt.colorbar()
  plt.title("Mel spectrogram", fontsize=20)
  plt.show()

import os

positiveFolderBasePath = "/content/drive/MyDrive/MiniProject2/Dataset/pos16kHz/" #1
negativeFolderBasePath = "/content/drive/MyDrive/MiniProject2/Dataset/neg16kHz/" #0
extracted_features = []

def features_extractor(file_name):
    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') 
    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)
    return mfccs_scaled_features

def get_features_from_folder(folder_name, label):
  for file in os.listdir(folder_name):
    extracted_features.append([features_extractor(folder_name + file), label])

get_features_from_folder(positiveFolderBasePath, 1)
get_features_from_folder(negativeFolderBasePath, 0)

extracted_features_df = pd.DataFrame(extracted_features,columns=['feature','class'])
extracted_features_df.head()

X = np.array(extracted_features_df['feature'].tolist())
y = np.array(extracted_features_df['class'].tolist())

from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
labelencoder=LabelEncoder()
y=to_categorical(labelencoder.fit_transform(y))

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)

"""The sequential API allows you to create models layer-by-layer for most problems.It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs.
the functional API allows you to create models that have a lot more flexibility as you can easily define models where layers connect to more than just the previous and next layers. In fact, you can connect layers to (literally) any other layer. As a result, creating complex networks such as siamese networks and residual networks become possible.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten
from tensorflow.keras.optimizers import Adam
from sklearn import metrics

num_labels=y.shape[1]

"""relu(rectified linear unit) = ReLU is the most commonly used activation function in neural networks, especially in CNNs. The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.

The softmax function is used as the activation function in the output layer of neural network models that predict a multinomial probability distribution. That is, softmax is used as the activation function for multi-class classification problems where class membership is required on more than two class labels.
"""

model=Sequential()

#1
model.add(Dense(100,input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))

#2
model.add(Dense(200))
model.add(Activation('relu'))
model.add(Dropout(0.5))

#3
model.add(Dense(100))
model.add(Activation('relu'))
model.add(Dropout(0.5))

#4
model.add(Dense(num_labels))
model.add(Activation('softmax'))

model.summary()

"""categorical_crossentropy = Used as a loss function for multi-class classification model where there are two or more output labels. The output label is assigned one-hot category encoding value in form of 0s and 1. The output label, if present in integer form, is converted into categorical encoding using keras.

adam = Adaptive Moment Estimation is an algorithm for optimization technique for gradient descent. The method is really efficient when working with large problem involving a lot of data or parameters. It requires less memory and is efficient.

.hdf5 = The Hierarchical Data Format version 5 (HDF5), is an open source file format that supports large, complex, heterogeneous data. HDF5 uses a "file directory" like structure that allows you to organize data within the file in many different structured ways, as you might do with files on your computer.
"""

model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')
from tensorflow.keras.callbacks import ModelCheckpoint
from datetime import datetime 
num_epochs = 100
num_batch_size = 32
checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/MiniProject2/audio_classification.hdf5', verbose=1, save_best_only=True)

start = datetime.now()
model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)
duration = datetime.now() - start
print("Training completed in time: ", duration)

test_accuracy=model.evaluate(X_test,y_test,verbose=0)
print(test_accuracy[1])

"""Argmax is an operation that finds the argument that gives the maximum value from a target function. Argmax is most commonly used in machine learning for finding the class with the largest predicted probability. Argmax can be implemented manually, although the argmax() NumPy function is preferred in practice."""

predict_x=model.predict(X_test) 
classes_x=np.argmax(predict_x,axis=1)
print(classes_x)

"""kaiser_fast = If you need to reduce load time, you can pass in an optional parameter to the load function. When using the default sample rate, the ‘kaiser_fast’ noticeably reduced the load time (~16 down to under 5), but the ‘scipy’ actually added time (85 seconds!!). When passing in sample rate as 11000, the ‘scipy’ it took about 67 second and ‘kaiser_best’ still came in fastest at about 4.85 sec."""

audio, sample_rate = librosa.load(positiveSampleFilepath, res_type='kaiser_fast') 
mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)
mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)
x_predict=model.predict(mfccs_scaled_features) 
predicted_label=np.argmax(x_predict,axis=1)
print(predicted_label)
prediction_class = labelencoder.inverse_transform(predicted_label) 
print(prediction_class)

audio, sample_rate = librosa.load(negativeSampleFilepath, res_type='kaiser_fast') 
mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)
mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)
x_predict=model.predict(mfccs_scaled_features) 
predicted_label=np.argmax(x_predict,axis=1)
print(predicted_label)
prediction_class = labelencoder.inverse_transform(predicted_label) 
print(prediction_class)